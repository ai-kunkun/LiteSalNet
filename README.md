# ğŸ“¢ LiteSalNet
A PyTorch implementation of LiteSalNet for Remote Sensing Salient Object Detection.

  <!-- ç¬¬ä¸€ä¸ªæŒ‰é’®ï¼šProject Page é¢œè‰² -->
  <a href="https://ai-kunkun.github.io/Niagara_page/"
     style="
       display: inline-block;
       background-color: #CF6F1C;
       color: #fff;
       padding: 0.5rem 1rem;
       text-decoration: none;
       border-radius: 4px;
       margin-right: 1rem;
     ">
    Check out more visual results
  </a>
</p>
<p align="center" style="margin: 1rem 0;">
  <!-- ç¬¬äºŒä¸ªæŒ‰é’®ï¼šArxiv é¢œè‰² -->
  <a href="https://ai-kunkun.github.io/Niagara_page/"
     style="
       display: inline-block;
       background-color: #A0D468;
       color: #fff;
       padding: 0.5rem 1rem;
       text-decoration: none;
       border-radius: 4px;
     ">
    Check out more numerical results
  </a>
</p>
# ğŸ¦‰ Network Architecture
![LiteSalNet Architecture](https://github.com/ai-kunkun/LiteSalNet/blob/main/image/LiteSalNet.png)

# ğŸ“ Requirements
- Python 3.7
- PyTorch 1.9.0

# ğŸ‰ Saliency maps
![LiteSalNet Architecture](https://github.com/ai-kunkun/LiteSalNet/blob/main/image/table.png)

# ğŸƒâ€â™‚ï¸ Data
Download this dataset and put it into datasets.

[LiteSalNet_data](https://pan.baidu.com/s/1JXwvfIvSVv0lXrDaNwxXuQ?pwd=AZXD) (code: AZXD) 
# ğŸš€ Training
Run train_LiteSalNet.py.

# ğŸ§© Pre-trained model and testing
Download the following pre-trained model and put them in ./models/LiteSalNet/, then run test_LiteSalNet.py. 

# ğŸ› ï¸ Evaluation Tool
You can use the [evaluation tool (MATLAB version)](https://github.com/MathLee/MatlabEvaluationTools) to evaluate the above saliency maps.
