# ğŸ“¢ LiteSalNet
A PyTorch implementation of LiteSalNet for Remote Sensing Salient Object Detection.
<p align="center">
  </br>
    <a href="https://arxiv.org/">
      <img src='https://img.shields.io/badge/Paper-Arxiv-green?style=for-the-badge&logo=adobeacrobatreader&logoWidth=20&logoColor=white&labelColor=66cc00&color=94DD15' alt='Paper PDF'>
    </a>
    <a href='https://ai-kunkun.github.io/Niagara_page/'>
      <img src='https://img.shields.io/badge/Project-Page-orange?style=for-the-badge&logo=Google%20chrome&logoColor=white&labelColor=D35400' alt='Project Page'></a>
    <a href="https://github.com/xianzuwu/Niagara">
      <img src='https://img.shields.io/badge/Code-Github-blue?style=for-the-badge&logo=github&logoColor=white&labelColor=181717' alt='Code Github'></a> 
      <br>
  </p>
  
# ğŸ¦‰ Network Architecture
![LiteSalNet Architecture](https://github.com/ai-kunkun/LiteSalNet/blob/main/image/LiteSalNet.png)

# ğŸ“ Requirements
- Python 3.7
- PyTorch 1.9.0

# ğŸ‰ Saliency maps
![LiteSalNet Architecture](https://github.com/ai-kunkun/LiteSalNet/blob/main/image/table.png)

# ğŸƒâ€â™‚ï¸ Data
Download this dataset and put it into datasets.

[LiteSalNet_data](https://pan.baidu.com/s/1JXwvfIvSVv0lXrDaNwxXuQ?pwd=AZXD) (code: AZXD) 
# ğŸš€ Training
Run train_LiteSalNet.py.

# ğŸ§© Pre-trained model and testing
Download the following pre-trained model and put them in ./models/LiteSalNet/, then run test_LiteSalNet.py. 

# ğŸ› ï¸ Evaluation Tool
You can use the [evaluation tool (MATLAB version)](https://github.com/MathLee/MatlabEvaluationTools) to evaluate the above saliency maps.
